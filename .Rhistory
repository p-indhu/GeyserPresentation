library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
cnames <- colnames(training)
x <- cnames[grep("^IL.*", cnames)]
x <- c(x, "diagnosis")
ttraining <- training[,x]
modelfit1 <- train(diagnosis ~ . , method = "glm", data = ttraining)
modelfit1
ttesting <- ttesting[,x]
ttesting <- testing[,x]
predict(modelfit1, newdata = ttesting[,-13])
testpc <- predict(modelfit1, newdata = ttesting[,-13])
confusionMatrix(ttesting$diagnosis, testpc)
testpc <- predict(modelfit2, newdata = ttesting[,-13])
preproc <- preProcess(ttraining[,-13], method = "pca", thresh = .80)
trainpc <- predict(preproc, ttraining[,-13])
modelfit2 <- train(ttraining$diagnosis ~ . , method = "glm", trainpc)
testpc <- predict(modelfit2, newdata = ttesting[,-13])
testpc <- predict(preproc, newdata = ttesting[,-13])
confusionMatrix(ttesting$diagnosis, testpc)
predict(modelfit2, testpc)
confusionMatrix(ttesting$diagnosis, predict(modelfit2, testpc))
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
training <- segmentationOriginal[segmentationOriginal$Case == "Train",]
testing <- segmentationOriginal[segmentationOriginal$Case == "Test",]
set.seed(125)
colnames(segmentationOriginal)
levels(segmentationOriginal$Class)
fit <- train(Class ~ ., method = "rpart", data = training)
fit$finalmodel
fit
library(rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot(fit$finalModel)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(fit$finalModel)
45*1000
45e+3
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
unique(olive$area)
unique(olive$Area)
fit <- train(Area ~ ., method = "rpart", data = olive)
newdata = as.data.frame(t(colMeans(olive)))
newdata
predict(fit, newdata = newdata)
predict(fit, newdata = newdata[-1,])
fit <- train(Area ~ ., method = "rpart2", data = olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(fit, newdata = newdata[-1,])
predict(fit, newdata = newdata)
fancyRpartPlot(fit$finalModel)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
training <- segmentationOriginal[segmentationOriginal$Case == "Train",]
testing <- segmentationOriginal[segmentationOriginal$Case == "Test",]
set.seed(125)
fit <- train(Class ~ ., method = "rpart", data = training)
fit$finalmodel
library(rattle)
fancyRpartPlot(fit$finalModel)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
fit<- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method = "glm", family = "binomial", data = trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
prediction <- predict(fit, newdata = trainSA)
values <- trainSA$chd
missClass(values, prediction)
prediction <- predict(fit, newdata = testSA)
values <- testSA$chd
missClass(values, prediction)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train
vowel.test
colnames(vowel.train)
l <- 1:10
class(l)
l <- factor(l)
class(l)
l
set.seed(33833)
?varImp
fit<- train(y ~ ., method = "rf", data = vowel.train)
varImp(fit)
?randomForest
fit1 <- randomForest(y ~ . , data = vowel.train)
varImp(fit1$finalModel)
varImp(fit1)
fit1$finalModel
fit$finalModel
varImp(fit$finalModel)
class(vowel.train$y)
vowel.train$y <- factor(y)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
fit1 <- randomForest(y ~ . , data = vowel.train)
varImp(fit1)
sort(varImp(fit1))
res <- varImp(fit1)
res
class(res)
res[,2]
dim(res)
sort(res$Overall)
res[order(res$Overall),]
res[order(-res$Overall),]
library(caret)
training <- read.csv("p,l-training.csv")
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
summary(training)
colnames(training)
head(training)
View(training)
plot(train$roll_belt, col=train$classe)
plot(training$roll_belt, col=training$classe)
is.na(training)
sum(is.na(training$roll_belt))
sum(is.na(training$pitch_belt))
sum(is.na(training$yaw_belt))
sum(is.na(training$total_accel_belt))
unique(training$total_accel_belt)
unique(training$kurtosis_roll_belt)
sum(is.na(training$kurtosis_roll_belt))
colnames(training)
plot(training$pitch_belt, col=training$classe)
plot(training$kurtosis_roll_belt, col=training$classe)
sum(is.na(training$gyros_belt_y))
sum(is.na(training$gyros_belt_x))
sum(is.na(training$gyros_belt_z))
cols <- colnames(training)
grep(cols, "kurtosis|skewness|max|min|amplitude|var_|avg_|stddev_|")
?grep
grep("kurtosis|skewness|max|min|amplitude|var_|avg_|stddev_|", cols)
grep("kurtosis|skewness|max|min|amplitude|var_|avg_|stddev_|", cols, value = TRUE)
grep("kurtosis", cols)
grep("kurtosis", cols, value = true)
grep("kurtosis", cols, value = TRUE)
grep("kurtosis|skewness", cols, value = TRUE)
grep("kurtosis|skewness|max", cols, value = TRUE)
grep("kurtosis|skewness|max|min|amplitude|var_|avg_|stddev_", cols, value = TRUE)
cols[!grep("kurtosis|skewness|max|min|amplitude|var_|avg_|stddev_", cols)]
cols[grep("kurtosis|skewness|max|min|amplitude|var_|avg_|stddev_", cols)]
grep("kurtosis|skewness|max|min|amplitude|var_|avg_|stddev_", cols)
grepl("kurtosis|skewness|max|min|amplitude|var_|avg_|stddev_", cols)
cols[!grepl("kurtosis|skewness|max|min|amplitude|var_|avg_|stddev_", cols)]
cols <- colnames(training)
cols <- cols[-1:7]
cols <- cols[8:160]
cols <- cols[!grepl("kurtosis|skewness|max|min|amplitude|var_|avg_|stddev_", cols)]
?select
library(dplyr)
?select
subset(training, select = cols)
training <- subset(training, select = cols)
View(training)
?filter
cols
set.seed(1234)
s <- sample(1:19622)
s <- s[1:2000]
trainsub <- training[s,]
?cov
?cor
nsv <- nearZeroVar(trainsub, saveMetrics = TRUE)
nsv
M <- abs(cor(trainsub[-53]))
diag(M) <- 0
which(M > 0.8, arr.ind = TRUE)
m
M
modelfit1 <- train(classe ~ ., method = "rf", data = trainsub)
modelfit1
modelfit2 <- train(classe ~ ., method = "rf", preprocess = "pca", data = trainsub)
modelfit2 <- train(classe ~ ., method = "glm", data = trainsub)
library(caret)
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
cols <- colnames(training)
cols <- cols[8:160]
cols <- cols[!grepl("kurtosis|skewness|max|min|amplitude|var_|avg_|stddev_", cols)]
training <- subset(training, select = cols)
set.seed(1234)
s <- s[1:2000]
trainsub <- training[s,]
set.seed(1234)
s<-sample(1:19622)
s <- s[1:2000]
trainsub <- training[s,]
modelfit2 <- train(classe ~ ., method = "glm", data = trainsub)
modelfit2 <- train(classe ~ ., method = "rf", preProcess = "pca", data = trainsub)
modelfit2
?registerDoParallel
library(doParallel)
?registerDoParallel
library(caret)
?trainControl
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
cols <- colnames(training)
cols <- cols[8:160]
cols <- cols[!grepl("kurtosis|skewness|max|min|amplitude|var_|avg_|stddev_", cols)]
training <- subset(training, select = cols)
set.seed(975)
inTrain = createDataPartition(training$classe, p = 0.60)[[1]]
trainsub = training[ inTrain,]
testsub = training[-inTrain,]
rm("training")
set.seed(12345)
modelfit1 <- train(classe ~ ., method = "rf", data = trainsub)
modelfit1
prediction <- predict(modelfit1, newdata=testsub)
?confusionMatrix
confusionMatrix(prediction, testsub$classe)
testprediction <- predict(modelfit1, newdata=testing)
confusionMatrix(testprediction, testing$classe)
levels(testing$classe
)
colnames(testing)
testing$problem_id
trainprediction <- predict(modelfit1, newdata = trainsub)
confusionMatrix(trainprediction, trainsub$classe)
testprediction
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(testprediction)
class(testprediction)
library(caret)
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
cols <- colnames(training)
cols <- cols[8:160]
cols <- cols[!grepl("kurtosis|skewness|max|min|amplitude|var_|avg_|stddev_", cols)]
training <- subset(training, select = cols)
set.seed(975)
inTrain = createDataPartition(training$classe, p = 0.60)[[1]]
trainsub = training[ inTrain,]
testsub = training[-inTrain,]
rm("training")
cor(train$classe, train[-53,])
cor(train$classe, trainsub[-53,])
cor(trainsub$classe, trainsub[-53,])
?confusionMatrix
?knit2html
knit2html("MLProject.Rmd")
library(knitr)
knit2html("MLProject.Rmd")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
view(vowel.train)
head(vowel.train)
head(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
modelfit1 <- train(y ~ ., method = "rf", data = vowel.train)
modelfit2 <- train(y ~ ., method = "gbm", data = vowel.train)
modelfit1
p1 <- predict(modelfit1, newdata = vowel.test)
p2 <- predict(modelfit2, newdata = vowel.test)
confusionMatrix(p1, vowel.test$y)
confusionMatrix(p2, vowel.test$y)
pp1 <- predict(modelfit1, newdata = vowel.train)
pp2 <- predict(modelfit2, newdata = vowel.train)
df <- data.frame(pp1,pp2, vowel.train$y)
modelfit3 <- train(vowel.train.y ~ ., method = "gam", data = df)
dfp <- predict(modelfit3, df)
ddf <- data.frame(p1,p2)
pp <- predict(modelfit3, ddf)
confusionMatrix(pp, vowel.test$y)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modelfit1 <- train(diagnosis ~ ., method = "rf", data = training)
modelfit2 <- train(diagnosis ~ ., method = "gbm", data = training)
modelfit3 <- train(diagnosis ~ ., method = "lda", data = training)
p1 <- predict(modelfit1, testing)
p2 <- predict(modelfit2, testing)
p3 <- predict(modelfit3, testing)
predDF <- data.frame(p1,p2,p3,diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~., method = "rf", data = predDF)
combpred <- predict(combModFit, predDF)
confusionMatrix(combpred, predDF$diagnosis)
confusionMatrix(p1, testing$diagnosis)
confusionMatrix(p2, testing$diagnosis)
confusionMatrix(p3, testing$diagnosis)
trainp1 <- predict(modelfit1, training)
trainp2 <- predict(modelfit2, training)
trainp3 <- predict(modelfit3, training)
trainpredDF <- data.frame(trainp1, trainp2, trainp3, training$diagnosis)
combModFit <- train(training.diagnosis ~ ., method = "rf", data = trainpredDF)
predDF <- data.frame(p1,p2,p3,diagnosis = testing$diagnosis)
combpred <- predict(combModFit, predDF)
confusionMatrix(combpred, testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
?lasso
?plot.enet
library(ggplot2)
?plot.enet
library(elasticnet)
install.packages("elasticnet")
library(elasticnet)
?plot.enet
modelfit <- train(CompressiveStrength ~ ., method = "lasso", data = training)
plot.enet(modelfit)
modelfit
modelfitcoef
set.seed(233)
modelfit <- train(CompressiveStrength ~ ., method = "lasso", data = training)
modelfit$finalModel
plot.enet(modelfit$finalModel)
m <- modelfit$finalModel
m
m$beta.pure
library(lubridate)
dat = read.csv("~/Desktop/gaData.csv")
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
install.packages(forecast)
install.packages("forecast")
library(forecast)
?bats
fit <- bats(training)
library(lubridate)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
fit <- bats(training)
fit <- bats(training$date)
plot(forecast(fit))
?forecast
f <- forecast(fit)
f
fit <- bats(tstrain)
forecast(fit)
testing$visitsTumblr
testing$visitsTumblr < 0
sum(testing$visitsTumblr < 0)
testing$visitsTumblr > 774.1413
sum(testing$visitsTumblr > 774.1413)
sum(testing$visitsTumblr > 714.6418)
27/235
17/235
1 - 0.07234043
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(e1071)
?svm
set.seed(325)
fit <- svm(CompressiveStrength ~ ., data = training)
p <- predict(fit, testing)
confusionMatrix(p, testing$CompressiveStrength)
?rmse
fit$finalModel
sqrt(sum((p - testing$CompressiveStrength)^2))
accuracy(p, testing$CompressiveStrength)
library(lubridate)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
fit <- bats(tstrain)
f <- forecast(fit)
f
View(training)
?forecast
View(training)
View(testing)
f <- forecast(fit, h = 235)
f
f <- forecast(fit, h = 235, level = 95)
f
x <- testing$visitsTumblr
f$Lo 95
f$Lo95
f$lower
l <- f$lower
u <- f$upper
x > l && x < u
x > l
sum(x > l)
sum(s < u)
sum(x < u)
226 / 235
library(manipulate)
library(mtcars)
data(mtcars)
cars <- as.data.frame(mtcars)
View(cars)
View(cars)
data(mtcars)
head(mtcars)
data(HairEyeColor)
head(HairEyeColor)
?HairEyeColor
?prob
data(iris)
head(iris)
?iris
summary(iris)
?father.son
data(father.son)
library(UsingR)
install.packages("UsingR")
data(father.son)
library(UsingR)
?father.son
data(father.son)
head(father.son)
data <- as.data.frame(father.son)
?galton
plot(father.son)
?lm
fit <- lm(sheight ~ fheight, data = heightdata)
heightdata <- as.data.frame(father.son)
fit <- lm(sheight ~ fheight, data = heightdata)
plot(fit)
fit
summary(fit)
sh <- predict(fit, heightdata$fheight)
sh <- predict(fit, newdata = heightdata$fheight)
library(caret)
set.seed(975)
inTrain = createDataPartition(heightdata$sheight, p = 0.80)[[1]]
trainsub = heightdata[ inTrain,]
testsub = heightdata[-inTrain,]
modelfit <- train(sheight ~ fheight, data = trainsub, method = "glm")
psheight <- predict(modelfit, data = trainsub)
psheight <- predict(modelfit, data = trainsub$fheight)
modelfit
psheight <- predict(modelfit, data = trainsub)
?predict
psheight <- predict(modelfit, newdata = trainsub)
confusionMatrix(psheight, trainsub$sheight)
psheight <- predict(modelfit, newdata = testsub)
res <- as.data.frame(psheight, testsub$sheight)
res <- as.data.frame(a = psheight, b = testsub$sheight)
cbind(a = psheight, b = testsub$sheight)
plot(father.son)
modelfit
?RMSE
cor(heightdata$sheight, heightdata$fheight)
psheight - testsub$sheight
summary(psheight - testsub$sheight)
setwd("C:/Users/Sriram/Desktop/Coursera/Working_Dir/geyser_eruption/")
library(slidify)
slidify('index.Rmd')
setwd("C:/Users/Sriram/Desktop/Coursera/Working_Dir/")
setwd("C:/Users/Sriram/Desktop/Coursera/Working_Dir/geyser_eruption/")
slidify
slidify('index.Rmd')
browseURL('index.html')
library(devtools)
library(slidify)
slidify('index.Rmd')
install_github('slidify','ramnathv')
install_github('slidifyLibraries', 'ramnathv')
library(slidify)
slidify('index.Rmd')
install_version("stringr", version="0.6.2")
install.packages("C:/Users/Sriram/Downloads/stringr_0.6.2.tar.gz", repos = NULL, type = "source")
